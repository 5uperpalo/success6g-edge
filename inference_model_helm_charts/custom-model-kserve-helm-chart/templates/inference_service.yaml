apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: {{ .Values.InferenceService.name }}
spec:
  predictor:
    # to disable scaling to zero
    minReplicas: 1
    serviceAccountName: {{ .Values.InferenceService.serviceAccountName }} 
    model:
      modelFormat:
        name: mlflow
      protocolVersion: v2
      storageUri: {{ .Values.InferenceService.storageUri }}
spec:
  predictor:
    # to disable scaling to zero
    minReplicas: 1
    containers:
      - name: custom-model-container
        image: 5uperpalo/success6g_custom_kserve:latest

